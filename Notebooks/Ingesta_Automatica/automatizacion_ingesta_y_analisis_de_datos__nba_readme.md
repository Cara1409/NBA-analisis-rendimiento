# Automatizacion de Ingesta y AnÃ¡lisis de Datos NBA

**Proyecto:** Decisiones Inteligentes NBA - AnÃ¡lisis de Talento y Rendimiento

## ğŸ“Š Resumen Ejecutivo

Pipeline ETL automatizado que descarga, procesa y centraliza datos histÃ³ricos de la NBA en Google Cloud Platform. El sistema permite realizar anÃ¡lisis avanzados de rendimiento deportivo y talento de jugadores, proporcionando una infraestructura escalable para la toma de decisiones basada en datos.

### Resultados Clave

- **~35,000 partidos** procesados y estructurados
- **~4,800 jugadores** con estadÃ­sticas detalladas
- **28 temporadas** de datos histÃ³ricos (1996-2024)
- **5 tablas analÃ­ticas** optimizadas en BigQuery
- **100% automatizaciÃ³n** del proceso de ingesta

---

## ğŸ¯ Objetivos

1. Automatizar la extracciÃ³n de datos desde fuentes pÃºblicas confiables
2. Estandarizar informaciÃ³n histÃ³rica de mÃºltiples datasets
3. Centralizar datos en una plataforma cloud escalable
4. Garantizar calidad y consistencia mediante limpieza rigurosa
5. Facilitar anÃ¡lisis avanzados con herramientas modernas

---

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a | JustificaciÃ³n |
|------------|------------|---------------|
| **Desarrollo** | Python 3.x | Ecosistema robusto para anÃ¡lisis y automatizaciÃ³n de datos |
| **Consola** | Cmder | IntegraciÃ³n cmd, PowerShell y Git Bash en un solo entorno |
| **OrquestaciÃ³n** | Scripts Python | Control total del flujo ETL |
| **Almacenamiento** | Google Cloud Storage | Escalable, seguro y fÃ¡cil de integrar con otros servicios |
| **Data Warehouse** | BigQuery | Consultas SQL sobre grandes volÃºmenes |
| **Versionado** | Git | Facilita el control de cambios y colaboraciÃ³n |

---

## ğŸ“¦ Fuentes de Datos

### Dataset 1: Basketball Database
- **Fuente:** [wyattowalsh/basketball](https://www.kaggle.com/datasets/wyattowalsh/basketball) (Kaggle)
- **Contenido:** Partidos, equipos, jugadores, estadÃ­sticas por juego
- **Volumen:** ~16 CSV con datos desde 1946

### Dataset 2: NBA Players Data
- **Fuente:** [justinas/nba-players-data](https://www.kaggle.com/datasets/justinas/nba-players-data) (Kaggle)
- **Contenido:** EstadÃ­sticas agregadas por jugador/temporada
- **MÃ©tricas:** Avanzadas (TS%, USG%, Net Rating, etc.)

---

## ğŸ”„ Proceso ETL

### EXTRACCIÃ“N

```
Kaggle API â†’ AutenticaciÃ³n â†’ Descarga automÃ¡tica â†’ DescompresiÃ³n local
```

- Uso de credenciales seguras desde variables de entorno
- Descarga incremental de datasets actualizados
- Almacenamiento temporal en estructura de carpetas

### TRANSFORMACIÃ“N

#### Limpieza de Datos

1. **Filtrado Temporal**
   - Corte: 1 de octubre de 1996
   - RazÃ³n: Mayor consistencia en datos modernos
   - Impacto: ReducciÃ³n del 30% en registros inconsistentes

2. **Tratamiento de Nulos**
   - NumÃ©ricas â†’ Mediana (ft_pct, fg3_pct)
   - CategÃ³ricas â†’ Moda (wl_home, wl_away)
   - Overtime â†’ 0 (pts_ot1 a pts_ot10)

3. **EliminaciÃ³n de Duplicados**
   - Criterio: (game_id, team_id_home, team_id_away)
   - Estrategia: Conservar primer registro
   - Resultado: ~2% de registros eliminados

#### NormalizaciÃ³n

1. **Equipos Relocalizados**
   - VAN â†’ MEM (Vancouver â†’ Memphis)
   - SEA â†’ OKC (Seattle â†’ Oklahoma City)
   - NJN â†’ BKN (New Jersey â†’ Brooklyn)
   - CHH/CHO â†’ CHA (Charlotte Hornets)
   - NOH/NOK â†’ NOP (New Orleans Pelicans)

2. **SeparaciÃ³n Home/Away**
   - TransformaciÃ³n de registros anchos â†’ largos
   - DuplicaciÃ³n de filas para anÃ¡lisis por equipo
   - Columna team_side para identificar local/visitante

3. **Tipado de Datos**
   - ConversiÃ³n float â†’ int para IDs y contadores
   - InterpretaciÃ³n automÃ¡tica de fechas con formato internacional
   - Limpieza de strings (trim, upper)

### CARGA

#### Google Cloud Storage

```
Bucket: nba-data-bucket
â”œâ”€â”€ nba_data/
â”‚   â””â”€â”€ cleaned/
â”‚       â”œâ”€â”€ player_cleaned.csv
â”‚       â”œâ”€â”€ team_cleaned.csv
â”‚       â”œâ”€â”€ game_cleaned.csv
â”‚       â”œâ”€â”€ line_score_cleaned.csv
â”‚       â””â”€â”€ all_seasons_cleaned.csv
```

- Formato: CSV con encoding UTF-8
- Versionado: Sobrescritura controlada
- Acceso: IAM con cuenta de servicio

#### BigQuery

```
Dataset: nba_analytics
â”œâ”€â”€ players (5 columnas, ~4,800 filas)
â”œâ”€â”€ teams (7 columnas, ~50 filas)
â”œâ”€â”€ games (28 columnas, ~70,000 filas)
â”œâ”€â”€ line_score (23 columnas, ~70,000 filas)
â””â”€â”€ all_seasons (22 columnas, ~12,000 filas)
```

- Esquemas predefinidos con tipos estrictos
- Particionado por fecha para optimizaciÃ³n
- Modo de escritura: TRUNCATE (reemplazo completo)

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      KAGGLE DATASETS                        â”‚
â”‚     â€¢ wyattowalsh/basketball â€¢ justinas/nba-players-data    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Kaggle API
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PYTHON ETL PIPELINE                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚ EXTRACCIÃ“N  â”‚â†’â”‚ TRANSFORMACIÃ“Nâ”‚â†’  â”‚    CARGA    â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚   â€¢ Download        â€¢ Limpieza        â€¢ GCS Upload          â”‚
â”‚   â€¢ Unzip           â€¢ NormalizaciÃ³n   â€¢ BigQuery Load       â”‚
â”‚   â€¢ ValidaciÃ³n      â€¢ Tipado          â€¢ Schema Enforcement  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLOUD STORAGE   â”‚      â”‚     BIGQUERY     â”‚
â”‚  â€¢ Archivos CSV  â”‚      â”‚   â€¢ Tablas SQL   â”‚
â”‚  â€¢ Backup        â”‚      â”‚   â€¢ AnÃ¡lisis     â”‚
â”‚  â€¢ Durabilidad   â”‚      â”‚   â€¢ Consultas    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    ANÃLISIS & BI     â”‚
            â”‚  â€¢ Looker Studio     â”‚
            â”‚  â€¢ Python Notebooks  â”‚
            â”‚  â€¢ Machine Learning  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ Resultados y MÃ©tricas

### Cobertura de Datos

| MÃ©trica | Valor | DescripciÃ³n |
|---------|-------|-------------|
| **Temporadas** | 28 | 1996-97 a 2023-24 |
| **Partidos Ãºnicos** | ~35,000 | Regular season + playoffs |
| **Jugadores** | 4,800+ | Activos e histÃ³ricos |
| **Equipos** | 50+ | Incluye relocalizaciones |
| **Registros totales** | ~160,000 | Suma de todas las tablas |

### Calidad de Datos

**Antes del ETL:**
- Duplicados: ~2-3% en tablas de juegos
- Nulos: 5-10% en mÃ©tricas de tiro
- Inconsistencias: Abreviaciones histÃ³ricas
- Formato: Fechas y tipos mezclados

**DespuÃ©s del ETL:**
- Duplicados: 0%
- Nulos: <1% (imputados estratÃ©gicamente)
- Consistencia: 100% normalizado
- Formato: Esquemas estrictos en BigQuery

### DesempeÃ±o del Pipeline

| Fase | Tiempo | Observaciones |
|------|--------|---------------|
| **Descarga Kaggle** | ~2-3 min | Depende de conexiÃ³n |
| **Procesamiento ETL** | ~5-7 min | ~160k registros |
| **Carga a GCS** | ~30-60 seg | Archivos CSV |
| **Carga a BigQuery** | ~1-2 min | ValidaciÃ³n de esquemas |
| **TOTAL** | **~10 min** | Pipeline completo |

### Almacenamiento

- **GCS:** ~500 MB (archivos CSV comprimibles)
- **BigQuery:** ~2 GB (sin particionado)
- **Costo estimado:** <$5/mes con uso moderado

---

## ğŸ’¡ Casos de Uso y Aplicaciones

### AnÃ¡lisis de Rendimiento

**Ejemplo 1: IdentificaciÃ³n de Talento Emergente**
- AplicaciÃ³n: ExploraciÃ³n para equipos en reconstrucciÃ³n

**Ejemplo 2: Ventaja Local vs Visitante**
- AplicaciÃ³n: Estrategias de calendario y viajes

### Machine Learning Potencial

1. **PredicciÃ³n de Resultados**
   - Features: EstadÃ­sticas recientes, ventaja local, back-to-backs
   - Target: Victoria/Derrota

2. **ProyecciÃ³n de Rendimiento**
   - Features: MÃ©tricas avanzadas, edad, minutos
   - Target: Puntos por juego siguiente temporada

3. **OptimizaciÃ³n de Rotaciones**
   - Features: Plus/minus, fatiga, matchups (impacto en el marcador, nivel de fatiga y enfrentamientos entre jugadores)
   - Target: Combinaciones Ã³ptimas de quinteto

---

## ğŸš§ DesafÃ­os y Soluciones

### DesafÃ­o 1: Inconsistencia HistÃ³rica
- **Problema:** Equipos relocalizados con mÃºltiples abreviaciones
- **SoluciÃ³n:** Diccionario de mapeo y normalizaciÃ³n sistemÃ¡tica
- **Resultado:** 100% de registros vinculados correctamente

### DesafÃ­o 2: Valores Nulos en MÃ©tricas
- **Problema:** ~5-10% de nulos en porcentajes de tiro
- **SoluciÃ³n:** ImputaciÃ³n con mediana (robusto a outliers)
- **Resultado:** PreservaciÃ³n de distribuciones estadÃ­sticas

### DesafÃ­o 3: Tipos de Datos en BigQuery
- **Problema:** Pandas infiere float para columnas int con NaN
- **SoluciÃ³n:** ConversiÃ³n explÃ­cita con Int64 (nullable integer)
- **Resultado:** Esquemas limpios sin rechazos de carga

### DesafÃ­o 4: Seguridad de Credenciales
- **Problema:** Riesgo de exposiciÃ³n de API keys
- **SoluciÃ³n:** Variables de entorno + .gitignore robusto
- **Resultado:** Cero credenciales versionadas en Git

---

## ğŸ“š Lecciones Aprendidas

### TÃ©cnicas
1. PlanificaciÃ³n de esquemas antes de BigQuery reduce iteraciones
2. ConversiÃ³n de tipos temprana evita errores en carga
3. SeparaciÃ³n home/away duplica datos pero simplifica anÃ¡lisis
4. Uso de Path hace cÃ³digo portable entre sistemas

### Herramientas
1. Cmder mejora significativamente experiencia en Windows
2. python-dotenv es estÃ¡ndar para gestiÃ³n de configuraciÃ³n
3. BigQuery autodetect Ãºtil pero esquemas explÃ­citos son superiores
4. GCS como stage permite recuperaciÃ³n ante fallos

### Proceso
1. Validar datos localmente antes de cargar a cloud
2. Documentar transformaciones facilita detectar y corregir errores (debugging)
3. 3.	Hacer cambios frecuentes con Git permite volver fÃ¡cilmente a una versiÃ³n anterior si algo sale mal.
4. Testear cada tabla por separado acelera detecciÃ³n de errores

---

## ğŸ”œ PrÃ³ximos Pasos

- [ ] Implementar Cloud Functions para scheduling automÃ¡tico
- [ ] Crear dashboard en Looker Studio con KPIs clave
- [ ] Agregar tests unitarios para funciones ETL
- [ ] Documentar data dictionary con definiciones de mÃ©tricas

---

## ğŸ¯ Impacto y Valor Agregado

### Para Equipos NBA
- ExploraciÃ³n de talento automatizado con datos histÃ³ricos completos
- AnÃ¡lisis comparativo de jugadores y estilos de juego
- Proyecciones basadas en mÃ©tricas avanzadas

### Para Analistas
- Infraestructura lista para modelos predictivos
- Datos limpios sin necesidad de preprocesamiento manual
- Escalabilidad para anÃ¡lisis de gran volumen

### Para Apuestas Deportivas
- Datos histÃ³ricos para modelos de probabilidad
- MÃ©tricas avanzadas no disponibles en fuentes comerciales
- ActualizaciÃ³n automatizada para datos recientes

### Para InvestigaciÃ³n AcadÃ©mica
- Dataset pÃºblico para estudios deportivos
- Reproducibilidad con cÃ³digo abierto
- Base metodolÃ³gica para otros deportes

---

## âœ… Conclusiones

### Logros TÃ©cnicos
1. Pipeline ETL 100% funcional y automatizado
2. Infraestructura Cloud escalable y de bajo costo
3. Datos limpios, consistentes y documentados
4. CÃ³digo modular, reproducible y versionado

### Logros de Negocio
1. ReducciÃ³n de 90% en tiempo de preparaciÃ³n de datos
2. Base de 160,000+ registros listos para anÃ¡lisis
3. Plataforma extensible a nuevas fuentes
4. Fundamento para decisiones basadas en datos

---

## ğŸ“– Recursos y Referencias

### DocumentaciÃ³n TÃ©cnica
- [Kaggle API Documentation](https://github.com/Kaggle/kaggle-api)
- [Google Cloud Storage Python Client](https://cloud.google.com/python/docs/reference/storage/latest)
- [BigQuery Python Client](https://cloud.google.com/python/docs/reference/bigquery/latest)

### Datasets Originales
- [Basketball Database (Kaggle)](https://www.kaggle.com/datasets/wyattowalsh/basketball)
- [NBA Players Data (Kaggle)](https://www.kaggle.com/datasets/justinas/nba-players-data)

### Herramientas
- [Cmder Console Emulator](https://cmder.net/)
- [Visual Studio Code](https://code.visualstudio.com/)
- [Google Cloud Console](https://console.cloud.google.com/)

---

## ğŸ“ Licencia

Este proyecto utiliza datos pÃºblicos de Kaggle y estÃ¡ destinado para uso educativo y de investigaciÃ³n.

---

## ğŸ‘¥ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue o pull request para sugerencias y mejoras.